{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Data prep\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer,LabelBinarizer, StandardScaler\n",
        "\n",
        "# Models\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import balanced_accuracy_score, accuracy_score, plot_confusion_matrix, roc_auc_score\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')\n",
        "\n",
        "MOVIES_FILEPATH = 'data/movies_raw.csv'\n",
        "\n",
        "movie_d_types = {\n",
        "    'year': object,\n",
        "    'genre': object,\n",
        "    'duration': int,\n",
        "    'actors': object,\n",
        "    'avg_vote': float,\n",
        "    'votes': int,\n",
        "    'reviews_from_users': float,\n",
        "    'reviews_from_critics':float\n",
        "}\n",
        "\n",
        "df = pd.read_csv(MOVIES_FILEPATH, header=0, dtype=movie_d_types)\n",
        "\n",
        "print(df.describe())\n",
        "\n",
        "# Remove features which are not used in the model\n",
        "removable_features = [\n",
        "    'title', \n",
        "    'original_title', \n",
        "    'description',\n",
        "    'usa_gross_income', \n",
        "    'worlwide_gross_income', \n",
        "    # Removed because of too many different currencies and a lot of null-values.\n",
        "    # Could potentially give more precise predictions.\n",
        "    'budget', \n",
        "    'metascore',\n",
        "    'imdb_title_id', \n",
        "    'language',\n",
        "    'director', \n",
        "    'writer', \n",
        "    'production_company'\n",
        "]\n",
        "df.drop(removable_features, axis=1, inplace=True)\n",
        "\n",
        "# Make year numeric or NaN\n",
        "df = df[pd.to_numeric(df['year'], errors='coerce').notnull()]\n",
        "\n",
        "# Helps us ensure all columns are displayed https://stackoverflow.com/a/25415404\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "# Get a summary of our dataset\n",
        "pd.DataFrame.hist(df, figsize = [15,15]);"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make USA_made"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def usa_made_assign(value):\n",
        "    if 'USA' in value.split(','):\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# Remove the few movies where country is na\n",
        "df = df[df['country'].notna()]\n",
        "df['country'] = df.apply(lambda row: usa_made_assign(row['country']), axis=1)\n",
        "df = df[pd.to_numeric(df['country'], errors='coerce').notnull()]\n",
        "df.rename(columns={'country': 'usa_made'})\n",
        "\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make season categories from date_published"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def season_assign(value):\n",
        "    if re.match(\"\\d{4}\\-(0?[1-9]|1[012])\\-(0?[1-9]|[12][0-9]|3[01])*\", value):\n",
        "        month = int(value.split('-')[1])\n",
        "        # between May and August\n",
        "        if 5 <= month <= 8:\n",
        "            return 'season_summer'\n",
        "        # November, December or January\n",
        "        elif month >= 11 or month == 1:\n",
        "            return 'season_winter'\n",
        "    return 'season_outof'\n",
        "\n",
        "# Generalize publish date to whether it is inside one of the large movie seasons, such as summer- or holiday-season.\n",
        "df['date_published'] = df.apply(lambda row: season_assign(row['date_published']), axis=1)\n",
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## make popular_actors from actors and actor_award_nominees.txt"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# read txt file of nomineed oscar actors to set of actors\n",
        "with open('generated/oscar/actor_award_nominees.txt') as f:\n",
        "    award_nomineed_actors = set(line.strip() for line in f)\n",
        "\n",
        "def has_popular_actor(actors):\n",
        "    if len(list(actors & award_nomineed_actors)) > 0:\n",
        "        return 1\n",
        "    return 0 \n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # convert genre- and actor strings to genre- and actor lists\n",
        "    row_genres = df.at[index, 'genre'].split(', ')\n",
        "    df.at[index, 'genre'] = row_genres\n",
        "\n",
        "    actors_set = set(str(row['actors']).split(', '))\n",
        "\n",
        "    # Store popular actor binary value in new column\n",
        "    df.at[index, 'popular_actor'] = has_popular_actor(actors_set)\n",
        "\n",
        "\n",
        "# Actors no longer needed\n",
        "df.drop(['actors'], axis=1, inplace=True)\n",
        "\n",
        "df[['popular_actor']] = df[['popular_actor']].apply(pd.to_numeric)\n",
        "df.head(20)\n",
        "\n",
        "# Builds statistics regarding average movie rating between for movies with or without popular actors\n",
        "actor_group = df[['popular_actor', 'avg_vote']].groupby('popular_actor').mean().reset_index()\n",
        "\n",
        "# See the average rating of movies with a popular actor and those without.\n",
        "print(actor_group.head())\n",
        "actor_group.plot.bar(x='popular_actor', y='avg_vote', rot=0, color=['gray', '#E24A38'], figsize=(15,10))"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target function"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def target_func(value):\n",
        "    if value >= 6:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "df['target'] = df.apply(lambda row: target_func(row['avg_vote']), axis=1)\n",
        "\n",
        "print(f'Percent of dataset in target: {round(df.avg_vote[df.avg_vote > 6.0].count()/df.avg_vote.count(),4)}')\n",
        "# remove avg_vote. No longer needed when having target\n",
        "df.drop(['avg_vote'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One hot encode genre and season"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# one-hot encode genre\n",
        "mlb = MultiLabelBinarizer()\n",
        "df = df.join(pd.DataFrame(mlb.fit_transform(df['genre']),columns=mlb.classes_, index=df.index))\n",
        "\n",
        "# one-hot encode seasons\n",
        "lb = LabelBinarizer()\n",
        "df = df.join(pd.DataFrame(lb.fit_transform(df[\"date_published\"]),index=df.index, columns=lb.classes_))\n",
        "\n",
        "#remove genre, date_published, and none-season after one-hot encoding it\n",
        "df.drop(['genre','date_published'], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 reviews are encoded as na. Convert to 0\n",
        "df[['reviews_from_users', 'reviews_from_critics']] = df[['reviews_from_users','reviews_from_critics']].fillna(value=0)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum(axis = 0)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make training and test data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# target\n",
        "y = df.target\n",
        "\n",
        "# Ensure target value is not part of X\n",
        "df.drop(['target'], axis=1, inplace=True)\n",
        "X = df\n",
        "\n",
        "# Split into training and testing data.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    # y is the target value \n",
        "    y,\n",
        "    # 25% of the X-entries was chosen for testing\n",
        "    test_size=0.25, \n",
        "    # Seed used when shuffling data. Uses a constant value for reproducable shuffling\n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "# fit and transform training data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# only transform the test data\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## kNN Method"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_classify(n_neighbors, weights):\n",
        "    knn = KNeighborsClassifier(\n",
        "        n_jobs=-1,\n",
        "        n_neighbors=n_neighbors,\n",
        "        weights=weights)\n",
        "\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "    y_pred = knn.predict(X_test_scaled)\n",
        "    \n",
        "    plot_confusion_matrix(knn, X_test_scaled, y_test,\n",
        "            display_labels=['High rating','Low rating'],\n",
        "            normalize='true', \n",
        "            cmap='Blues')\n",
        "\n",
        "    return round(balanced_accuracy_score(y_test, y_pred),3)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### kNN with default parameters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "default_balanced_accuracy_knn = knn_classify(5, 'uniform')\n",
        "print(f'Balanced accuracy score: {default_balanced_accuracy_knn}')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### grid search kNN"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "knn_params = {\n",
        "    # odd numbers between 1 and 100\n",
        "   'n_neighbors': list(range(1,100,2)),\n",
        "   'weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn_grid_search_cv = GridSearchCV(knn, knn_params, verbose=2, cv=3, n_jobs=-1)\n",
        "knn_grid_search_cv.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_parameters_knn = knn_grid_search_cv.best_params_"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if you wish to run the tuned knn with hardcoded tuning parameters.\n",
        "# Useful if you do not wish to run GridSearchCV again.\n",
        "# tuned_parameters_knn = {'n_neighbors': 59, 'weights':'distance'}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### kNN with tuned parameters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_balanced_accuracy_knn = knn_classify(tuned_parameters_knn['n_neighbors'], tuned_parameters_knn['weights'])\n",
        "\n",
        "print(f'Balanced accuracy score: {tuned_balanced_accuracy_knn}')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree Method"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def d_tree_classify(max_depth, min_samples_split, min_samples_leaf):\n",
        "    if max_depth:\n",
        "        d_tree = DecisionTreeClassifier(\n",
        "                max_depth=max_depth,\n",
        "                min_samples_leaf=min_samples_leaf,\n",
        "                min_samples_split=min_samples_split)\n",
        "    else:\n",
        "        d_tree = DecisionTreeClassifier(\n",
        "                min_samples_leaf=min_samples_leaf,\n",
        "                min_samples_split=min_samples_split)\n",
        "\n",
        "    d_tree = d_tree.fit(X_train, y_train)\n",
        "    dt_y_pred = d_tree.predict(X_test)\n",
        "\n",
        "    plot_confusion_matrix(d_tree, X_test, y_test, \n",
        "            display_labels=['High rating','Low rating'],\n",
        "            normalize='true', \n",
        "            cmap='Blues')\n",
        "    \n",
        "    return balanced_accuracy_score(y_test, dt_y_pred)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision tree with default *parameters*"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "default_balanced_accuracy_dt = d_tree_classify(None, 2, 1)\n",
        "print(f'Balanced accuracy score: {default_balanced_accuracy_dt}')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### grid search Decision Tree"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tree_params = {\n",
        "   'max_depth': list(range(5,16)),\n",
        "   'min_samples_split': list(range(1,41)),\n",
        "   'min_samples_leaf': list(range(1,21))\n",
        "}\n",
        "\n",
        "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), tree_params, verbose=2, cv=3, n_jobs=-1)\n",
        "d_tree = grid_search_cv.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_parameters_dt = grid_search_cv.best_params_\n",
        "# tuned_parameters_dt = {'max_depth': 11, 'min_samples_leaf': 16, 'min_samples_split':37}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision tree with tuned *parameters*"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_balanced_accuracy_dt = d_tree_classify(**tuned_parameters_dt)\n",
        "print(f'Balanced accuracy score: {tuned_balanced_accuracy_dt}')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}